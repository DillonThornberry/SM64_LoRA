import json

'''
Step 4: Final preprocessing step

* Gets data from wiki_clean.json (generated by cleanjson.py)
* Replaces special characters and removes redundant phrases
* Puts text in prompt-response format for training LLM
* Stores output in sm64.jsonl (final file used for training)

'''

# Load JSON from file
with open('wiki_clean.json', 'r') as file:
    data = json.load(file)

output = []

# Replace special chars and remove redundant phrases
for key in data:
    prompt = key.split('/')[-1]
    prompt = " ".join(prompt.split('_'))
    prompt = " - ".join(prompt.split('#'))
    prompt = "'".join(prompt.split('%27'))
    prompt = "Explain " + prompt

    answer = data[key]
    
    answer = " ".join(answer.split('\n'))

    if answer.startswith("This article is a  stub"):
        answer = answer[98:]

    # Set up prompt-response format
    line = {"prompt": prompt, "completion": answer}
    output.append(line)



# Save the updated JSON to a file
output_file = "../data/sm64.jsonl"

# Writing the list to a JSONL file
with open(output_file, 'w') as f:
    for item in output:
        json.dump(item, f)
        f.write("\n")  # Ensure each dictionary is written on a new line

print(f"Data has been written to {output_file}")